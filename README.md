# NNL
Dans cette lab, l'objectif principal est de maîtriser l'utilisation de la bibliothèque PyTorch dans des tâches de classification, notamment à travers la mise en œuvre d'architectures de réseaux neuronaux profonds (DNN) 
ou de perceptrons multicouches (MLP). Le processus commence par des techniques de prétraitement appliquées à un ensemble de données donné, y compris le nettoyage des données et la standardisation/normalisation
pour garantir la cohérence des échelles de caractéristiques. Des techniques d'analyse exploratoire des données (EDA) sont ensuite utilisées pour comprendre la structure de l'ensemble de données et visualiser 
les modèles pertinents.
Pour résoudre le problème du déséquilibre des classes, des techniques d'augmentation des données sont appliquées, améliorant ainsi la capacité du modèle à gérer différentes instances. Par la suite, une architecture
DNN a été construite à l'aide de PyTorch pour résoudre des tâches de classification multi-classes. Optimisez les hyperparamètres, y compris le taux d'apprentissage, l'optimiseur, les époques et l'architecture du modèle
, pour obtenir un modèle efficace à l'aide de l'outil GridSearch de la bibliothèque scikit-learn
Des visualisations de la perte et de la précision à travers les époques ont été créées et interprétées pour évaluer les performances du modèle. Des mesures telles que la précision, la sensibilité et le score F1
sont calculées pour les ensembles de données d'entraînement et de test afin de fournir une évaluation complète. Enfin, diverses techniques de régularisation sont appliquées à l'architecture et les résultats obtenus
sont comparés au modèle initial pour mieux comprendre l'impact de la régularisation sur les performances de classification. Cette approche globale vise à promouvoir une compréhension holistique des tâches de 
classification PyTorch et des complexités impliquées dans l'optimisation et l'évaluation des modèles.
